LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type         | Params | Mode
-----------------------------------------------
0 | feat  | PointNetfeat | 2.8 M  | train
1 | conv1 | Conv1d       | 557 K  | train
2 | conv2 | Conv1d       | 131 K  | train
3 | conv3 | Conv1d       | 32.9 K | train
4 | conv4 | Conv1d       | 2.1 K  | train
5 | bn1   | BatchNorm1d  | 1.0 K  | train
6 | bn2   | BatchNorm1d  | 512    | train
7 | bn3   | BatchNorm1d  | 256    | train
-----------------------------------------------
3.5 M     Trainable params
0         Non-trainable params
3.5 M     Total params
14.117    Total estimated model params size (MB)
39        Modules in train mode
0         Modules in eval mode
Sanity Checking DataLoader 0:   0%|                                                                                                                                            | 0/2 [00:00<?, ?it/s]
/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.
/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.
Traceback (most recent call last):
  File "/root/pointnet.pytorch/utils/train_segmentation.py", line 155, in <module>
    trainer.fit(model, train_dataloader, val_dataloader)
  File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 539, in fit
    call._call_and_handle_interrupt(
  File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 575, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 982, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1024, in _run_stage
    self._run_sanity_check()
  File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/trainer.py", line 1053, in _run_sanity_check
    val_loop.run()
  File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/utilities.py", line 179, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 144, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 433, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/call.py", line 323, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/pytorch_lightning/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/pointnet.pytorch/pointnet/model.py", line 96, in validation_step
    logs = self._forward(points, target, mode="val")
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/pointnet.pytorch/pointnet/model.py", line 74, in _forward
    loss = F.nll_loss(pred, target)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/conda/lib/python3.11/site-packages/torch/nn/functional.py", line 2778, in nll_loss
    return torch._C._nn.nll_loss_nd(input, target, weight, _Reduction.get_enum(reduction), ignore_index)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: Expected input batch_size (160000) to match target batch_size (40000).
