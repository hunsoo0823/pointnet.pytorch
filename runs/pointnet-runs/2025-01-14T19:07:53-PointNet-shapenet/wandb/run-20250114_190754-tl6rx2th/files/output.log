LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name    | Type         | Params | Mode
-------------------------------------------------
0 | feat    | PointNetfeat | 2.8 M  | train
1 | fc1     | Linear       | 524 K  | train
2 | fc2     | Linear       | 131 K  | train
3 | fc3     | Linear       | 4.1 K  | train
4 | dropout | Dropout      | 0      | train
5 | bn1     | BatchNorm1d  | 1.0 K  | train
6 | bn2     | BatchNorm1d  | 512    | train
7 | relu    | ReLU         | 0      | train
-------------------------------------------------
3.5 M     Trainable params
0         Non-trainable params
3.5 M     Total params
13.861    Total estimated model params size (MB)
39        Modules in train mode
0         Modules in eval mode
Epoch 0:  12%|████████████████▉                                                                                                                         | 42/342 [00:03<00:24, 12.44it/s, v_num=x2th]
/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:476: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.
/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.
/opt/conda/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.

Detected KeyboardInterrupt, attempting graceful shutdown ...
