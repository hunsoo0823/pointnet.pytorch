LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
  | Name    | Type         | Params
-----------------------------------------
0 | feat    | PointNetfeat | 8.7 M
1 | fc1     | Linear       | 2.1 M
2 | fc2     | Linear       | 534 K
3 | fc3     | Linear       | 8.4 K
4 | dropout | Dropout      | 0
5 | bn1     | BatchNorm1d  | 2.0 K
6 | bn2     | BatchNorm1d  | 1.0 K
7 | relu    | ReLU         | 0
-----------------------------------------
11.4 M    Trainable params
0         Non-trainable params
11.4 M    Total params
45.466    Total estimated model params size (MB)
/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:492: Your `val_dataloader`'s sampler has shuffling enabled, it is strongly recommended that you turn shuffling off for val/test dataloaders.
/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=19` in the `DataLoader` to improve performance.
/tmp/ipykernel_103148/3123419004.py:137: UserWarning:
The version_base parameter is not specified.
Please specify a compatability version level, or None.
Will assume defaults for version 1.1
  hydra.initialize(config_path=None)
wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)
opt:
  optimizers:
  - name: RAdam
    kwargs:
      lr: 0.001
  lr_schedulers:
  - name: LinearWarmupLR
    kwargs:
      warm_end_steps: 1000
data:
  name: shapenet
  data_root: /root/share/pointnet.pytorch/data
  num_points: 2500
model:
  name: PointNet
  cls:
    layer1:
      in_feature: 2028
      out_feature: 1024
    layer2:
      in_feature: 1024
      out_feature: 521
    layer3:
      in_feature: 521
      out_feature: 16
    dropout: 0.3
  densecls:
    k: 16
    layer1:
      conv1d_in_channel: 1088
      conv1d_out_channel: 512
      conv1d_kernel_size: 1
    layer2:
      conv1d_in_channel: 512
      conv1d_out_channel: 256
      conv1d_kernel_size: 1
    layer3:
      conv1d_in_channel: 256
      conv1d_out_channel: 128
      conv1d_kernel_size: 1
    layer4:
      conv1d_in_channel: 128
      conv1d_kernel_size: 1
  feat:
    layer1:
      conv1d_in_channel: 3
      conv1d_out_channel: 128
      conv1d_kernel_size: 1
    layer2:
      conv1d_in_channel: 128
      conv1d_out_channel: 256
      conv1d_kernel_size: 1
    layer3:
      conv1d_in_channel: 256
      conv1d_out_channel: 2048
      conv1d_kernel_size: 1
    global_feat: true
    feature_transform: true
  stn:
    k: 64
    layer1:
      conv1d_in_channel: 3
      conv1d_out_channel: 128
      conv1d_kernel_size: 1
    layer2:
      conv1d_in_channel: 128
      conv1d_out_channel: 256
      conv1d_kernel_size: 1
    layer3:
      conv1d_in_channel: 256
      conv1d_out_channel: 2028
      conv1d_kernel_size: 1
    layer4:
      fc1_in_features: 2028
      fc1_out_features: 1024
    layer5:
      fc2_in_features: 1024
      fc2_out_features: 512
    layer6:
      fc3_in_features: 512
      fc3_out_features: 9
train:
  train_batch_size: 32
  val_batch_size: 16
  test_batch_size: 32
  train_val_split:
  - 0.9
  - 0.1
  run_root_dir: /root/share/pointnet.pytorch/runs/pointnet-runs/2024-06-04T08:42:25-PointNet-shapenet
  trainer_kwargs:
    accelerator: auto
    max_epochs: 50
    val_check_interval: 1.0
    log_every_n_steps: 100
log:
  loggers:
    WandbLogger:
      project: pointNet
      name: 2024-06-04T08:42:25-PointNet-shapenet
      tags:
      - fastcampus_de_en_translate_tutorials
      save_dir: /root/share/pointnet.pytorch/runs/pointnet-runs/2024-06-04T08:42:25-PointNet-shapenet
  callbacks:
    ModelCheckpoint:
      save_top_k: 3
      monitor: val_loss
      mode: min
      verbose: true
      dirpath: /root/share/pointnet.pytorch/runs/pointnet-runs/2024-06-04T08:42:25-PointNet-shapenet/weights
      filename: '{epoch}-{val_loss:.3f}'
    EarlyStopping:
      monitor: val_loss
      mode: min
      patience: 3
      verbose: true
{'Airplane': 0, 'Bag': 1, 'Cap': 2, 'Car': 3, 'Chair': 4, 'Earphone': 5, 'Guitar': 6, 'Knife': 7, 'Lamp': 8, 'Laptop': 9, 'Motorbike': 10, 'Mug': 11, 'Pistol': 12, 'Rocket': 13, 'Skateboard': 14, 'Table': 15}
{'Airplane': 4, 'Bag': 2, 'Cap': 2, 'Car': 4, 'Chair': 4, 'Earphone': 3, 'Guitar': 3, 'Knife': 2, 'Lamp': 4, 'Laptop': 2, 'Motorbike': 6, 'Mug': 2, 'Pistol': 3, 'Rocket': 3, 'Skateboard': 3, 'Table': 3} 4
{'Airplane': 0, 'Bag': 1, 'Cap': 2, 'Car': 3, 'Chair': 4, 'Earphone': 5, 'Guitar': 6, 'Knife': 7, 'Lamp': 8, 'Laptop': 9, 'Motorbike': 10, 'Mug': 11, 'Pistol': 12, 'Rocket': 13, 'Skateboard': 14, 'Table': 15}
{'Airplane': 4, 'Bag': 2, 'Cap': 2, 'Car': 4, 'Chair': 4, 'Earphone': 3, 'Guitar': 3, 'Knife': 2, 'Lamp': 4, 'Laptop': 2, 'Motorbike': 6, 'Mug': 2, 'Pistol': 3, 'Rocket': 3, 'Skateboard': 3, 'Table': 3} 4
16
PointNetCls(
  (feat): PointNetfeat(
    (stn): STN3d(
      (conv1): Conv1d(3, 128, kernel_size=(1,), stride=(1,))
      (conv2): Conv1d(128, 256, kernel_size=(1,), stride=(1,))
      (conv3): Conv1d(256, 2028, kernel_size=(1,), stride=(1,))
      (fc1): Linear(in_features=2028, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=512, bias=True)
      (fc3): Linear(in_features=512, out_features=9, bias=True)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn3): BatchNorm1d(2028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (conv1): Conv1d(3, 128, kernel_size=(1,), stride=(1,))
    (conv2): Conv1d(128, 256, kernel_size=(1,), stride=(1,))
    (conv3): Conv1d(256, 2048, kernel_size=(1,), stride=(1,))
    (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (bn3): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (fstn): STNkd(
      (conv1): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
      (conv2): Conv1d(128, 256, kernel_size=(1,), stride=(1,))
      (conv3): Conv1d(256, 2028, kernel_size=(1,), stride=(1,))
      (fc1): Linear(in_features=2028, out_features=1024, bias=True)
      (fc2): Linear(in_features=1024, out_features=512, bias=True)
      (fc3): Linear(in_features=512, out_features=4096, bias=True)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn3): BatchNorm1d(2028, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn4): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (bn5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU()
    )
  )
  (fc1): Linear(in_features=2028, out_features=1024, bias=True)
  (fc2): Linear(in_features=1024, out_features=521, bias=True)
  (fc3): Linear(in_features=521, out_features=16, bias=True)
  (dropout): Dropout(p=0.3, inplace=False)
  (bn1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn2): BatchNorm1d(521, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU()
